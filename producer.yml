version: '3.0'  # 使用 Docker Compose 的版本 3.0，適合大部分部署場景

services:
  producer_crawler_tw:  # 定義一個服務，名稱為 crawler_twse
    image: joycehsu65/web_crawler:${DOCKER_IMAGE_VERSION}  # ! 使用的映像檔名稱與標籤（版本）
    # image: winston07291/web_crawler_tw:${DOCKER_IMAGE_VERSION}
    hostname: "producer_crawler_tw"  # 設定 hostname = producer_crawler_finmind_duplicate
    command: pipenv run python crawler/producer_main_tw.py
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        # 設定在
        # node label producer = true 的機器上執行
        constraints: [node.labels.producer == true]
    restart: on-failure  # 失敗才重啟, 不要頻繁重啟, 發送任務
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - etf_lib_network  # 將此服務連接到 my_swarm_network 網路

  producer_crawler_us:  # 定義一個服務，名稱為 crawler_twse
    image: joycehsu65/web_crawler:${DOCKER_IMAGE_VERSION}  # ! 使用的映像檔名稱與標籤（版本）
    # image: winston07291/web_crawler_tw:${DOCKER_IMAGE_VERSION}
    hostname: "producer_crawler_us"  # 設定 hostname = producer_crawler_finmind_duplicate
    command: pipenv run python crawler/producer_main_us.py
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        # 設定在
        # node label producer = true 的機器上執行
        constraints: [node.labels.producer == true]
    restart: on-failure  # 失敗才重啟, 不要頻繁重啟, 發送任務
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - etf_lib_network  # 將此服務連接到 my_swarm_network 網路  

networks:
  etf_lib_network:
    # 加入已經存在的網路
    external: true
